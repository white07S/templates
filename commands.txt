Here you go — minimal, to-the-point, and ready to paste.

main.py (FastAPI, async streaming -> OpenAI)

# main.py
import os
import asyncio
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from openai import AsyncOpenAI

# Set OPENAI_API_KEY in your env
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # narrow in prod
    allow_methods=["*"],
    allow_headers=["*"],
)

class ChatIn(BaseModel):
    query: str
    model: str | None = "gpt-4o-mini"  # pick any chat model you have access to

@app.post("/chat")
async def chat(body: ChatIn):
    async def token_stream():
        # Stream tokens from OpenAI and yield them directly to the client
        stream = await client.chat.completions.create(
            model=body.model,
            messages=[{"role": "user", "content": body.query}],
            stream=True,
        )
        async for chunk in stream:
            delta = chunk.choices[0].delta
            if delta and delta.content:
                # yield raw text chunks; browser will render progressively
                yield delta.content
            await asyncio.sleep(0)

    return StreamingResponse(
        token_stream(),
        media_type="text/plain",
        headers={"Cache-Control": "no-cache"},
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)

app.js (React — simple page that streams)

// app.js
import React, { useState, useRef } from "react";

export default function App() {
  const [input, setInput] = useState("");
  const [output, setOutput] = useState("");
  const [loading, setLoading] = useState(false);
  const abortRef = useRef(null);

  const onSubmit = async (e) => {
    e.preventDefault();
    setOutput("");
    setLoading(true);

    const controller = new AbortController();
    abortRef.current = controller;

    try {
      const res = await fetch("http://localhost:8000/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ query: input }),
        signal: controller.signal,
      });

      if (!res.ok || !res.body) {
        const msg = await res.text().catch(() => "");
        throw new Error(msg || `HTTP ${res.status}`);
      }

      const reader = res.body.getReader();
      const decoder = new TextDecoder();

      while (true) {
        const { value, done } = await reader.read();
        if (done) break;
        setOutput((prev) => prev + decoder.decode(value));
      }
    } catch (err) {
      setOutput((prev) => prev + `\n[error] ${err.message || err}`);
    } finally {
      setLoading(false);
      abortRef.current = null;
    }
  };

  return (
    <div style={{ maxWidth: 800, margin: "40px auto", fontFamily: "ui-sans-serif, system-ui" }}>
      <h1>Streaming Test</h1>
      <form onSubmit={onSubmit} style={{ display: "flex", gap: 8 }}>
        <input
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="Ask something…"
          style={{ flex: 1, padding: 10, fontSize: 16 }}
        />
        <button type="submit" disabled={loading} style={{ padding: "10px 16px", fontSize: 16 }}>
          {loading ? "Streaming…" : "Send"}
        </button>
        {loading && (
          <button
            type="button"
            onClick={() => abortRef.current?.abort()}
            style={{ padding: "10px 16px", fontSize: 16 }}
          >
            Cancel
          </button>
        )}
      </form>

      <div style={{ marginTop: 16, padding: 12, background: "#f7f7f7", borderRadius: 8 }}>
        <div style={{ fontWeight: 600, marginBottom: 8 }}>Output</div>
        <pre style={{ whiteSpace: "pre-wrap", wordBreak: "break-word", margin: 0 }}>{output}</pre>
      </div>
    </div>
  );
}

Quick run:
	•	Backend: pip install fastapi uvicorn openai pydantic → python main.py
	•	Frontend: place app.js as your root component (e.g., src/App.jsx) and run your React dev server.
	•	Ensure OPENAI_API_KEY is set.

(OpenAI’s SDK supports token streaming from Chat Completions; details in official docs.)  ￼
