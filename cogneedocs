import cognee
import asyncio
os.environ["DO_NOT_TRACK"] = "1"
os.environ["TELEMETRY_DISABLED"] = "1"
os.environ["ANALYTICS_DISABLED"] = "1"
os.environ["NO_ANALYTICS"] = "1"

async def main():
    # Configure LLM (your local vLLM)
    cognee.config.llm_provider = "custom"
    cognee.config.llm_model = "your-model-name"
    cognee.config.llm_endpoint = "http://localhost:8000/v1"
    cognee.config.llm_api_key = "EMPTY"
    
    # Configure embeddings (also your local vLLM)
    cognee.config.embedding_provider = "custom"
    cognee.config.embedding_model = "your-embedding-model-name"
    cognee.config.embedding_endpoint = "http://localhost:8000/v1/embeddings"
    cognee.config.embedding_api_key = "EMPTY"
    cognee.config.embedding_dimensions = 1536  # Adjust for your model
    
    # Your cognee workflow
    await cognee.add("Your text data here")
    await cognee.cognify()
    results = await cognee.search("Your query here")
    
    for result in results:
        print(result)

asyncio.run(main())
